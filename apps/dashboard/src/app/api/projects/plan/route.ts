import { NextRequest, NextResponse } from 'next/server';
import { getDb } from '@ai-engine/db';
import { MemoryService, EmbeddingService, ProjectMemoryService } from '@ai-engine/memory';
import { createPlanningTools, getPlanningModeSystemPrompt } from '@ai-engine/agent-runtime';

export const dynamic = 'force-dynamic';

// Initialize services (in production, these would be singletons)
const embeddingService = new EmbeddingService();
const memoryService = new MemoryService(embeddingService);
const projectMemoryService = new ProjectMemoryService(memoryService, embeddingService);

/**
 * Generate AI planning response using memory-based context
 * This endpoint is called by the planning mode UI
 */
export async function POST(request: NextRequest) {
  try {
    const body = await request.json();
    const { projectId, userMessage, conversationHistory } = body;

    if (!projectId || !userMessage) {
      return NextResponse.json({ error: 'projectId and userMessage are required' }, { status: 400 });
    }

    const db = getDb();

    // Get project details
    const project = await db.project.findUnique({ where: { id: projectId } });
    if (!project) {
      return NextResponse.json({ error: 'Project not found' }, { status: 404 });
    }

    // Extract and store memories from user message
    // This happens BEFORE we build context, so new information is immediately available
    // Pass userId if available to separate user info from project requirements
    const userId = body.userId; // Get from auth/session
    await projectMemoryService.extractPlanningMemories(
      projectId,
      userMessage,
      '', // AI response will be stored after generation
      userId,
    );

    // Retrieve relevant context from PROJECT memory ONLY
    // This searches scope='team'/scopeOwnerId=projectId exclusively
    // User memories (scope='personal') are NOT included to prevent pollution
    const relevantMemories = await projectMemoryService.getRelevantContext(
      projectId,
      userMessage,
      15, // Limit to 15 most relevant project memories
    );

    // Build AI context from memories
    const memoryContext = relevantMemories
      .map((m) => {
        const confidence = m.finalScore >= 0.7 ? '★★★' : m.finalScore >= 0.5 ? '★★' : '★';
        return `${confidence} ${m.content}`;
      })
      .join('\n');

    // Get planning mode system prompt with capability restrictions
    const baseSystemPrompt = getPlanningModeSystemPrompt(project.name);
    
    const systemPrompt = `${baseSystemPrompt}

${project.description ? `\nProject Description: ${project.description}` : ''}

## Relevant Project Knowledge (from previous discussions)
${memoryContext || 'No prior context yet - this is the beginning of our planning conversation.'}

Use your available tools to research, gather information, and systematically document the project requirements in memory.`;

    // Build planning-specific tools
    const planningTools = createPlanningTools(projectMemoryService, projectId);

    // TODO: Integrate with ChatExecutor here
    // const chatExecutor = new ChatExecutor(llmPool, options);
    // Filter tools to only planning-allowed ones
    // const filteredTools = filterToolsForPlanning(allTools);
    // const result = await chatExecutor.execute(messages, systemPrompt, filteredTools);

    // For now, return a mock response showing memory-based context
    const aiResponse = `I understand. Based on our discussion so far and what I know about the project:

${relevantMemories.length > 0 ? `**Key Points from Our Discussion:**
${relevantMemories.slice(0, 5).map((m, i) => `${i + 1}. ${m.content.substring(0, 100)}...`).join('\n')}
` : ''}

Let me ask some clarifying questions to better understand your vision...

[This response would be generated by the LLM using the memory-based context]`;

    // Store AI response memories
    // Extracts both project requirements and user info if present
    await projectMemoryService.extractPlanningMemories(
      projectId,
      userMessage,
      aiResponse,
      userId,
    );

    // Save conversation to database (for audit trail, not for context)
    await db.projectConversation.create({
      data: {
        projectId,
        role: 'user',
        content: userMessage,
      },
    });

    await db.projectConversation.create({
      data: {
        projectId,
        role: 'assistant',
        content: aiResponse,
        metadata: {
          memoriesUsed: relevantMemories.length,
          contextTokensApprox: Math.ceil(memoryContext.length / 4),
          toolsAvailable: planningTools.length,
        },
      },
    });

    return NextResponse.json({
      response: aiResponse,
      context: {
        memoriesUsed: relevantMemories.length,
        contextTokens: Math.ceil((systemPrompt.length + aiResponse.length) / 4),
        planningToolsAvailable: planningTools.length,
      },
    });
  } catch (err: any) {
    console.error('Planning error:', err);
    return NextResponse.json({ error: err.message }, { status: 500 });
  }
}

/**
 * Generate PRD and tasks using comprehensive memory consolidation
 */
export async function PUT(request: NextRequest) {
  try {
    const body = await request.json();
    const { projectId } = body;

    if (!projectId) {
      return NextResponse.json({ error: 'projectId is required' }, { status: 400 });
    }

    // Use deep search to gather ALL project knowledge (ONLY from project scope)
    // This searches scope='team'/scopeOwnerId=projectId exclusively
    // User memories are NOT included - only project requirements with zero decay
    const comprehensiveKnowledge = await projectMemoryService.getComprehensiveKnowledge(
      projectId,
      'project requirements goals features architecture technical specifications',
      50, // Get comprehensive context (all project memories)
    );

    // Consolidate into structured categories (requirements, decisions, constraints, features)
    const consolidated = await projectMemoryService.consolidateProjectKnowledge(projectId);

    // TODO: Call LLM to generate PRD and tasks using consolidated knowledge
    // The consolidated knowledge provides a complete picture without overwhelming context

    return NextResponse.json({
      prd: '[Generated PRD would go here]',
      tasks: [],
      context: {
        totalMemories: comprehensiveKnowledge.length,
        requirements: consolidated.requirements.length,
        decisions: consolidated.decisions.length,
        constraints: consolidated.constraints.length,
        features: consolidated.features.length,
      },
    });
  } catch (err: any) {
    console.error('PRD generation error:', err);
    return NextResponse.json({ error: err.message }, { status: 500 });
  }
}
